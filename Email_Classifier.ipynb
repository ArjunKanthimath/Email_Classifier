{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48yfuJPZ0DcF",
        "outputId": "d9633d0f-8970-4d8a-8a90-8d7111477b96",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastapi\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.34.1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (2.11.3)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.72.0)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.13.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.4.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvicorn, python-dotenv, starlette, fastapi\n",
            "Successfully installed fastapi-0.115.12 python-dotenv-1.1.0 starlette-0.46.2 uvicorn-0.34.1\n",
            "Collecting en-core-web-lg==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.7/400.7 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install fastapi uvicorn pydantic spacy pandas openai python-dotenv scikit-learn\n",
        "!python -m spacy download en_core_web_lg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install transformers datasets scikit-learn pandas numpy spacy fastapi uvicorn pydantic python-multipart\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "# Create project directories\n",
        "!mkdir -p model_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZTuTX59JtndR",
        "outputId": "a75ded61-4de7-441e-97c2-06fe2ebf1fe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.115.12)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.34.1)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (2.11.3)\n",
            "Collecting python-multipart\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.46.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.13.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi) (4.9.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, python-multipart, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 python-multipart-0.0.20 xxhash-3.5.0\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m125.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile utils.py\n",
        "import re\n",
        "import spacy\n",
        "from typing import List, Dict, Tuple, Any\n",
        "from datetime import datetime\n",
        "\n",
        "class PiiMasker:\n",
        "    \"\"\"Enhanced PII masking with more precise pattern matching\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize with spaCy model and enhanced patterns\"\"\"\n",
        "        self.nlp = self._load_spacy_model()\n",
        "\n",
        "        # More precise regex patterns\n",
        "        self.patterns = {\n",
        "            \"email\": r'\\b[\\w\\.\\+\\-]+@[\\w\\-]+\\.[\\w\\.\\-]+\\b',\n",
        "            \"phone_number\": r'(?:\\+?\\d{1,3}[-.\\s]?)?\\(?\\d{2,4}\\)?[-.\\s]?\\d{2,4}[-.\\s]?\\d{2,5}\\b',\n",
        "            \"aadhar_num\": r'\\b\\d{4}[\\s\\-]?\\d{4}[\\s\\-]?\\d{4}\\b',\n",
        "            \"credit_debit_no\": r'\\b(?:\\d[ \\-]*?){13,19}\\b',\n",
        "            \"cvv_no\": r'(?<!\\d)\\b\\d{3,4}\\b(?!\\d)',\n",
        "            \"expiry_no\": r'\\b(?:0[1-9]|1[0-2])[/\\-](?:20)?\\d{2}\\b',\n",
        "            \"dob\": r'\\b(?:0[1-9]|[12][0-9]|3[01])[/\\-](?:0[1-9]|1[0-2])[/\\-](?:19|20)\\d{2}\\b',\n",
        "            \"account_id\": r'\\b(?:[A-Za-z]+[ \\-_]?)?\\d{4,}\\b',\n",
        "            \"ssn\": r'\\b\\d{3}[ \\-]?\\d{2}[ \\-]?\\d{4}\\b'\n",
        "        }\n",
        "\n",
        "        self.compiled_patterns = {k: re.compile(v, re.IGNORECASE) for k, v in self.patterns.items()}\n",
        "\n",
        "    def _load_spacy_model(self):\n",
        "        \"\"\"Load spaCy model with more conservative name detection\"\"\"\n",
        "        try:\n",
        "            nlp = spacy.load(\"en_core_web_sm\")\n",
        "            # Only detect proper nouns as names\n",
        "            ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
        "            patterns = [\n",
        "                {\"label\": \"PERSON\", \"pattern\": [\n",
        "                    {\"POS\": \"PROPN\", \"OP\": \"+\"},\n",
        "                    {\"POS\": \"PROPN\", \"OP\": \"*\"}\n",
        "                ]}\n",
        "            ]\n",
        "            ruler.add_patterns(patterns)\n",
        "            return nlp\n",
        "        except OSError:\n",
        "            import subprocess\n",
        "            import sys\n",
        "            subprocess.run([sys.executable, \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"], check=True)\n",
        "            return self._load_spacy_model()\n",
        "\n",
        "    def _is_valid_name(self, text):\n",
        "        \"\"\"Validate detected names to reduce false positives\"\"\"\n",
        "        # Skip single-word names unless they're clearly proper nouns\n",
        "        words = text.split()\n",
        "        if len(words) == 1:\n",
        "            return False\n",
        "        # Skip names that are too long (likely not actual names)\n",
        "        if len(words) > 3:\n",
        "            return False\n",
        "        # Skip names that are all lowercase\n",
        "        if text.islower():\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    def extract_masked_entities(self, text: str) -> Tuple[str, List[Dict[str, Any]]]:\n",
        "        \"\"\"More precise PII extraction\"\"\"\n",
        "        text = text.replace('\\r\\n', '\\n')\n",
        "        entities = []\n",
        "        masked_text = text\n",
        "\n",
        "        # Process with regex patterns first\n",
        "        for entity_type, pattern in self.compiled_patterns.items():\n",
        "            for match in pattern.finditer(text):\n",
        "                if any(self._is_overlap(match.start(), match.end(), e) for e in entities):\n",
        "                    continue\n",
        "                entities.append({\n",
        "                    \"start_index\": match.start(),\n",
        "                    \"end_index\": match.end(),\n",
        "                    \"entity_type\": entity_type,\n",
        "                    \"entity_value\": match.group()\n",
        "                })\n",
        "\n",
        "        # Process with spaCy NER (more conservative)\n",
        "        doc = self.nlp(text)\n",
        "        for ent in doc.ents:\n",
        "            if ent.label_ == \"PERSON\" and self._is_valid_name(ent.text):\n",
        "                if not any(self._is_overlap(ent.start_char, ent.end_char, e) for e in entities):\n",
        "                    entities.append({\n",
        "                        \"start_index\": ent.start_char,\n",
        "                        \"end_index\": ent.end_char,\n",
        "                        \"entity_type\": \"full_name\",\n",
        "                        \"entity_value\": ent.text\n",
        "                    })\n",
        "\n",
        "        # Sort and mask\n",
        "        entities.sort(key=lambda x: x[\"start_index\"])\n",
        "        for entity in sorted(entities, key=lambda x: x[\"start_index\"], reverse=True):\n",
        "            masked_text = (\n",
        "                masked_text[:entity[\"start_index\"]] +\n",
        "                f\"[{entity['entity_type']}]\" +\n",
        "                masked_text[entity[\"end_index\"]:]\n",
        "            )\n",
        "\n",
        "        return masked_text, entities\n",
        "\n",
        "    def _is_overlap(self, start: int, end: int, entity: Dict) -> bool:\n",
        "        \"\"\"Check for entity overlaps\"\"\"\n",
        "        return not (end <= entity[\"start_index\"] or start >= entity[\"end_index\"])\n",
        "\n",
        "def mask_email(email_body: str) -> Tuple[str, List[Dict[str, Any]]]:\n",
        "    \"\"\"Interface for PII masking\"\"\"\n",
        "    masker = PiiMasker()\n",
        "    return masker.extract_masked_entities(email_body)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_glGMa_Fohfr",
        "outputId": "cf3e1da1-f0e5-405e-95aa-29b4d38a18a6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile models.py\n",
        "import os\n",
        "import pickle\n",
        "import logging\n",
        "import torch\n",
        "import pandas as pd\n",
        "from typing import List, Tuple\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    BertTokenizer, BertForSequenceClassification,\n",
        "    AdamW, get_linear_schedule_with_warmup\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class EmailDataset(Dataset):\n",
        "    \"\"\"Dataset for email classification.\"\"\"\n",
        "\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=256):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "class EmailClassifier:\n",
        "    \"\"\"BERT-based email classifier.\"\"\"\n",
        "\n",
        "    def __init__(self, device=None, model_dir='./model_data'):\n",
        "        self.device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.model_dir = model_dir\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        self.label_mapping = {}\n",
        "        self.inverse_label_mapping = {}\n",
        "        self.model = None\n",
        "\n",
        "        os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "    def prepare_data(self, data_csv: str) -> Tuple[List[str], List[int]]:\n",
        "        logger.info(f\"Loading data from {data_csv}\")\n",
        "        df = pd.read_csv(data_csv)\n",
        "\n",
        "        if 'email' not in df.columns or 'type' not in df.columns:\n",
        "            raise ValueError(\"CSV must have 'email' and 'type' columns\")\n",
        "\n",
        "        df = df.dropna(subset=['email', 'type'])\n",
        "\n",
        "        unique_labels = df['type'].unique()\n",
        "        self.label_mapping = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "        self.inverse_label_mapping = {idx: label for label, idx in self.label_mapping.items()}\n",
        "\n",
        "        with open(os.path.join(self.model_dir, 'label_mapping.pkl'), 'wb') as f:\n",
        "            pickle.dump({\n",
        "                'label_mapping': self.label_mapping,\n",
        "                'inverse_label_mapping': self.inverse_label_mapping\n",
        "            }, f)\n",
        "\n",
        "        texts = df['email'].tolist()\n",
        "        labels = [self.label_mapping[label] for label in df['type']]\n",
        "\n",
        "        return texts, labels\n",
        "\n",
        "    def train(self, data_csv: str, epochs=4, batch_size=16, learning_rate=2e-5):\n",
        "        texts, labels = self.prepare_data(data_csv)\n",
        "\n",
        "        train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "            texts, labels, test_size=0.2, random_state=42\n",
        "        )\n",
        "\n",
        "        train_dataset = EmailDataset(train_texts, train_labels, self.tokenizer)\n",
        "        val_dataset = EmailDataset(val_texts, val_labels, self.tokenizer)\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "        num_labels = len(self.label_mapping)\n",
        "        self.model = BertForSequenceClassification.from_pretrained(\n",
        "            'bert-base-uncased', num_labels=num_labels\n",
        "        )\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        optimizer = AdamW(self.model.parameters(), lr=learning_rate)\n",
        "        total_steps = len(train_loader) * epochs\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer, num_warmup_steps=0, num_training_steps=total_steps\n",
        "        )\n",
        "\n",
        "        best_val_accuracy = 0\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            logger.info(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "            self.model.train()\n",
        "            total_loss = 0\n",
        "\n",
        "            for batch in train_loader:\n",
        "                optimizer.zero_grad()\n",
        "                input_ids = batch['input_ids'].to(self.device)\n",
        "                attention_mask = batch['attention_mask'].to(self.device)\n",
        "                labels = batch['label'].to(self.device)\n",
        "\n",
        "                outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                loss = outputs.loss\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            avg_loss = total_loss / len(train_loader)\n",
        "            logger.info(f\"Average training loss: {avg_loss:.4f}\")\n",
        "\n",
        "            # Validation\n",
        "            self.model.eval()\n",
        "            val_preds, val_true = [], []\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for batch in val_loader:\n",
        "                    input_ids = batch['input_ids'].to(self.device)\n",
        "                    attention_mask = batch['attention_mask'].to(self.device)\n",
        "                    labels = batch['label'].to(self.device)\n",
        "\n",
        "                    outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                    preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
        "                    val_preds.extend(preds)\n",
        "                    val_true.extend(labels.cpu().numpy())\n",
        "\n",
        "            val_accuracy = accuracy_score(val_true, val_preds)\n",
        "            logger.info(f\"Validation accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "            if val_accuracy > best_val_accuracy:\n",
        "                best_val_accuracy = val_accuracy\n",
        "                logger.info(f\"Saving best model with accuracy: {val_accuracy:.4f}\")\n",
        "                self.save_model()\n",
        "\n",
        "                report = classification_report(\n",
        "                    val_true, val_preds,\n",
        "                    target_names=[self.inverse_label_mapping[i] for i in range(num_labels)],\n",
        "                    digits=4\n",
        "                )\n",
        "                logger.info(f\"Classification Report:\\n{report}\")\n",
        "\n",
        "        return best_val_accuracy\n",
        "\n",
        "    def save_model(self):\n",
        "        if self.model:\n",
        "            self.model.save_pretrained(self.model_dir)\n",
        "            self.tokenizer.save_pretrained(self.model_dir)\n",
        "            logger.info(f\"Model saved to {self.model_dir}\")\n",
        "        else:\n",
        "            logger.warning(\"No model to save.\")\n",
        "\n",
        "    def load_model(self):\n",
        "        try:\n",
        "            with open(os.path.join(self.model_dir, 'label_mapping.pkl'), 'rb') as f:\n",
        "                mappings = pickle.load(f)\n",
        "                self.label_mapping = mappings['label_mapping']\n",
        "                self.inverse_label_mapping = mappings['inverse_label_mapping']\n",
        "\n",
        "            self.model = BertForSequenceClassification.from_pretrained(self.model_dir)\n",
        "            self.tokenizer = BertTokenizer.from_pretrained(self.model_dir)\n",
        "            self.model.to(self.device)\n",
        "            self.model.eval()\n",
        "\n",
        "            logger.info(f\"Model loaded from {self.model_dir}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error loading model: {e}\")\n",
        "            return False\n",
        "\n",
        "    def predict(self, text: str) -> str:\n",
        "        if self.model is None:\n",
        "            if not self.load_model():\n",
        "                raise ValueError(\"Model not loaded. Please train or load a model first.\")\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=256,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        input_ids = encoding['input_ids'].to(self.device)\n",
        "        attention_mask = encoding['attention_mask'].to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            pred = torch.argmax(outputs.logits, dim=1).item()\n",
        "\n",
        "        return self.inverse_label_mapping[pred]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTCoMAnxsSj8",
        "outputId": "da267704-3e4f-465a-b78f-7bceef3eba52"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing models.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Dict, Any\n",
        "import uvicorn\n",
        "import logging\n",
        "\n",
        "from models import EmailClassifier\n",
        "from utils import mask_email\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "app = FastAPI(title=\"Email Classification API\",\n",
        "              description=\"API for classifying and masking PII in support emails\")\n",
        "\n",
        "# Initialize classifier\n",
        "classifier = EmailClassifier()\n",
        "model_loaded = classifier.load_model()\n",
        "if not model_loaded:\n",
        "    logger.warning(\"Model not loaded. Please train or load a model before making predictions.\")\n",
        "\n",
        "class EmailRequest(BaseModel):\n",
        "    \"\"\"Request model for email classification\"\"\"\n",
        "    email_body: str\n",
        "\n",
        "class EmailResponse(BaseModel):\n",
        "    \"\"\"Response model for email classification\"\"\"\n",
        "    input_email_body: str\n",
        "    list_of_masked_entities: List[Dict[str, Any]]\n",
        "    masked_email: str\n",
        "    category_of_the_email: str\n",
        "\n",
        "@app.post(\"/classify\", response_model=EmailResponse)\n",
        "async def classify_email(request: EmailRequest):\n",
        "    \"\"\"\n",
        "    Classify email and mask PII.\n",
        "\n",
        "    Parameters:\n",
        "    - email_body: The email text to classify\n",
        "\n",
        "    Returns:\n",
        "    - input_email_body: Original email text\n",
        "    - list_of_masked_entities: List of detected PII entities\n",
        "    - masked_email: Email with PII masked\n",
        "    - category_of_the_email: Predicted email category\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Check if email body is provided\n",
        "        if not request.email_body or len(request.email_body.strip()) == 0:\n",
        "            raise HTTPException(status_code=400, detail=\"Email body cannot be empty\")\n",
        "\n",
        "        # Mask PII entities\n",
        "        masked_email, entities = mask_email(request.email_body)\n",
        "\n",
        "        # Classify the masked email\n",
        "        category = classifier.predict(masked_email)\n",
        "\n",
        "        # Format the response\n",
        "        response = {\n",
        "            \"input_email_body\": request.email_body,\n",
        "            \"list_of_masked_entities\": entities,\n",
        "            \"masked_email\": masked_email,\n",
        "            \"category_of_the_email\": category\n",
        "        }\n",
        "\n",
        "        return response\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error processing request: {e}\", exc_info=True)\n",
        "        raise HTTPException(status_code=500, detail=f\"Error processing request: {str(e)}\")\n",
        "\n",
        "@app.get(\"/health\")\n",
        "async def health_check():\n",
        "    \"\"\"Health check endpoint\"\"\"\n",
        "    if model_loaded:\n",
        "        return {\"status\": \"ok\", \"model_loaded\": True}\n",
        "    else:\n",
        "        return {\"status\": \"warning\", \"model_loaded\": False,\n",
        "                \"message\": \"Model not loaded. Please train or load a model.\"}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    uvicorn.run(\"app:app\", host=\"0.0.0.0\", port=8000, reload=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2PLPqjFs0KB",
        "outputId": "e5c428ac-071b-4254-e07e-9465abbdb3d8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train.py\n",
        "import argparse\n",
        "import logging\n",
        "import torch\n",
        "from models import EmailClassifier\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def train_model(data_path, epochs=4, batch_size=16, learning_rate=2e-5):\n",
        "    \"\"\"\n",
        "    Train the email classification model.\n",
        "\n",
        "    Args:\n",
        "        data_path: Path to the CSV file containing emails and their categories\n",
        "        epochs: Number of training epochs\n",
        "        batch_size: Batch size for training\n",
        "        learning_rate: Learning rate for the optimizer\n",
        "    \"\"\"\n",
        "    logger.info(f\"Training model with data from {data_path}\")\n",
        "\n",
        "    # Detect GPU/CPU device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    logger.info(f\"📦 Using device: {device}\")\n",
        "\n",
        "    # Initialize classifier with device\n",
        "    classifier = EmailClassifier(device=device)\n",
        "\n",
        "    # Train model\n",
        "    accuracy = classifier.train(\n",
        "        data_csv=data_path,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        learning_rate=learning_rate\n",
        "    )\n",
        "\n",
        "    logger.info(f\"✅ Training completed. Best validation accuracy: {accuracy:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser(description=\"Train email classification model\")\n",
        "    parser.add_argument(\"--data\", type=str, required=True, help=\"Path to the CSV data file\")\n",
        "    parser.add_argument(\"--epochs\", type=int, default=4, help=\"Number of training epochs\")\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=16, help=\"Batch size for training\")\n",
        "    parser.add_argument(\"--lr\", type=float, default=2e-5, help=\"Learning rate\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    train_model(args.data, args.epochs, args.batch_size, args.lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHmc2HNHtDLf",
        "outputId": "86d88236-27e6-46ac-b227-08553d804191"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test.py\n",
        "import argparse\n",
        "import logging\n",
        "import json\n",
        "from models import EmailClassifier\n",
        "from utils import mask_email\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def test_classification(email_text):\n",
        "    \"\"\"\n",
        "    Test the email classification and PII masking.\n",
        "\n",
        "    Args:\n",
        "        email_text: Email text to classify\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Initialize classifier\n",
        "        classifier = EmailClassifier()\n",
        "        success = classifier.load_model()\n",
        "\n",
        "        if not success:\n",
        "            logger.error(\"Failed to load model. Please train or load a model first.\")\n",
        "            return\n",
        "\n",
        "        # Mask PII\n",
        "        logger.info(\"Masking PII...\")\n",
        "        masked_email, entities = mask_email(email_text)\n",
        "\n",
        "        # Classify email\n",
        "        logger.info(\"Classifying email...\")\n",
        "        category = classifier.predict(masked_email)\n",
        "\n",
        "        # Format response\n",
        "        response = {\n",
        "            \"input_email_body\": email_text,\n",
        "            \"list_of_masked_entities\": entities,\n",
        "            \"masked_email\": masked_email,\n",
        "            \"category_of_the_email\": category\n",
        "        }\n",
        "\n",
        "        # Print results\n",
        "        logger.info(\"Results:\")\n",
        "        logger.info(f\"Category: {category}\")\n",
        "        logger.info(f\"Masked email: {masked_email}\")\n",
        "        logger.info(f\"Found {len(entities)} PII entities\")\n",
        "\n",
        "        print(json.dumps(response, indent=2))\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error testing classification: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser(description=\"Test email classification and PII masking\")\n",
        "    parser.add_argument(\"--email\", type=str, required=True, help=\"Email text to classify\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    test_classification(args.email)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts23pc56tUYz",
        "outputId": "e4d7e068-1a80-4bdf-e5b3-f8a8a6419a70"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app_hf.py\n",
        "from fastapi import FastAPI, HTTPException, Request, Form\n",
        "from fastapi.responses import JSONResponse, HTMLResponse\n",
        "from fastapi.templating import Jinja2Templates\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Dict, Any\n",
        "import logging\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import json\n",
        "import sys\n",
        "\n",
        "from models import EmailClassifier\n",
        "from utils import PiiMasker\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "app = FastAPI(\n",
        "    title=\"Email Classification API\",\n",
        "    description=\"API for classifying and masking PII in support emails\"\n",
        ")\n",
        "\n",
        "# Setup templates for the web interface\n",
        "templates = Jinja2Templates(directory=str(Path(__file__).parent / \"templates\"))\n",
        "\n",
        "# Initialize classifier with proper device handling\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "classifier = EmailClassifier(device=device, model_dir=\"./model_data\")\n",
        "model_loaded = classifier.load_model()\n",
        "if not model_loaded:\n",
        "    logger.warning(\"Model not loaded. This is expected if you need to train first.\")\n",
        "\n",
        "# Initialize PII masker\n",
        "try:\n",
        "    pii_masker = PiiMasker()\n",
        "except Exception as e:\n",
        "    logger.error(f\"Failed to initialize PII masker: {e}\")\n",
        "    raise RuntimeError(\"Failed to initialize PII masker\") from e\n",
        "\n",
        "class EmailRequest(BaseModel):\n",
        "    \"\"\"Request model for email classification\"\"\"\n",
        "    email_body: str\n",
        "\n",
        "class EmailResponse(BaseModel):\n",
        "    \"\"\"Response model for email classification\"\"\"\n",
        "    input_email_body: str\n",
        "    list_of_masked_entities: List[Dict[str, Any]]\n",
        "    masked_email: str\n",
        "    category_of_the_email: str\n",
        "\n",
        "@app.post(\"/classify\", response_model=EmailResponse)\n",
        "async def classify_email(request: EmailRequest):\n",
        "    \"\"\"Classify email and mask PII\"\"\"\n",
        "    try:\n",
        "        if not model_loaded and not classifier.load_model():\n",
        "            raise HTTPException(status_code=500, detail=\"Model not loaded or trained\")\n",
        "\n",
        "        if not request.email_body or len(request.email_body.strip()) == 0:\n",
        "            raise HTTPException(status_code=400, detail=\"Email body cannot be empty\")\n",
        "\n",
        "        masked_email, entities = pii_masker.extract_masked_entities(request.email_body)\n",
        "        logger.info(f\"Entities returned from mask_email: {entities}\")\n",
        "        category = classifier.predict(masked_email)\n",
        "\n",
        "        # Safely format the response\n",
        "        safe_entities = [\n",
        "            {\n",
        "                \"position\": [\n",
        "                    entity.get(\"start_index\", 0),\n",
        "                    entity.get(\"end_index\", 0)\n",
        "                ],\n",
        "                \"classification\": entity.get(\"entity_type\", \"unknown\"),\n",
        "                \"entity\": entity.get(\"entity_value\", \"\")\n",
        "            } for entity in entities\n",
        "        ]\n",
        "\n",
        "        return {\n",
        "            \"input_email_body\": request.email_body,\n",
        "            \"list_of_masked_entities\": safe_entities,\n",
        "            \"masked_email\": masked_email,\n",
        "            \"category_of_the_email\": category\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error processing request: {e}\", exc_info=True)\n",
        "        raise HTTPException(status_code=500, detail=f\"Error processing request: {str(e)}\")\n",
        "\n",
        "@app.get(\"/\", response_class=HTMLResponse)\n",
        "async def read_root(request: Request):\n",
        "    \"\"\"Serve the web interface\"\"\"\n",
        "    return templates.TemplateResponse(\"index.html\", {\n",
        "        \"request\": request,\n",
        "        \"show_results\": False,\n",
        "        \"device\": str(device)\n",
        "    })\n",
        "\n",
        "@app.post(\"/\", response_class=HTMLResponse)\n",
        "async def process_email(request: Request, email_body: str = Form(...)):\n",
        "    \"\"\"Process email from web form\"\"\"\n",
        "    try:\n",
        "        if not model_loaded and not classifier.load_model():\n",
        "            return templates.TemplateResponse(\"index.html\", {\n",
        "                \"request\": request,\n",
        "                \"error\": \"Model not loaded or trained\",\n",
        "                \"show_results\": False\n",
        "            })\n",
        "\n",
        "        if not email_body or len(email_body.strip()) == 0:\n",
        "            return templates.TemplateResponse(\"index.html\", {\n",
        "                \"request\": request,\n",
        "                \"error\": \"Email body cannot be empty\",\n",
        "                \"show_results\": False\n",
        "            })\n",
        "\n",
        "        masked_email, entities = pii_masker.extract_masked_entities(email_body)\n",
        "        logger.info(f\"Entities returned from mask_email: {entities}\")\n",
        "        category = classifier.predict(masked_email)\n",
        "\n",
        "        # Safely format the JSON response\n",
        "        formatted_json = {\n",
        "            \"input_email_body\": email_body,\n",
        "            \"list_of_masked_entities\": [\n",
        "                {\n",
        "                    \"position\": [\n",
        "                        entity.get(\"start_index\", 0),\n",
        "                        entity.get(\"end_index\", 0)\n",
        "                    ],\n",
        "                    \"classification\": entity.get(\"entity_type\", \"unknown\"),\n",
        "                    \"entity\": entity.get(\"entity_value\", \"\")\n",
        "                } for entity in entities\n",
        "            ],\n",
        "            \"masked_email\": masked_email,\n",
        "            \"category_of_the_email\": category\n",
        "        }\n",
        "\n",
        "        # Pretty print the JSON\n",
        "        pretty_json = json.dumps(formatted_json, indent=2, ensure_ascii=False)\n",
        "\n",
        "        return templates.TemplateResponse(\"index.html\", {\n",
        "            \"request\": request,\n",
        "            \"input_email_body\": email_body,\n",
        "            \"masked_email\": masked_email,\n",
        "            \"category\": category,\n",
        "            \"entities\": entities,\n",
        "            \"show_results\": True,\n",
        "            \"device\": str(device),\n",
        "            \"formatted_json\": pretty_json\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error processing request: {e}\", exc_info=True)\n",
        "        return templates.TemplateResponse(\"index.html\", {\n",
        "            \"request\": request,\n",
        "            \"error\": f\"Error processing request: {str(e)}\",\n",
        "            \"show_results\": False\n",
        "        })\n",
        "\n",
        "@app.get(\"/health\")\n",
        "async def health_check():\n",
        "    \"\"\"Health check endpoint\"\"\"\n",
        "    return {\n",
        "        \"status\": \"ok\" if model_loaded else \"warning\",\n",
        "        \"model_loaded\": model_loaded,\n",
        "        \"device\": str(device),\n",
        "        \"message\": \"\" if model_loaded else \"Model not loaded. Please train or load a model.\"\n",
        "    }\n",
        "\n",
        "@app.exception_handler(Exception)\n",
        "async def global_exception_handler(request: Request, exc: Exception):\n",
        "    logger.error(f\"Global exception: {exc}\", exc_info=True)\n",
        "    return JSONResponse(\n",
        "        status_code=500,\n",
        "        content={\"detail\": f\"An unexpected error occurred: {str(exc)}\"}\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxJ_hH72tca6",
        "outputId": "64eb6bc2-0b03-436b-b734-c1101fed6667"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app_hf.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "# Core ML/DL dependencies\n",
        "torch==2.0.1\n",
        "transformers==4.33.2\n",
        "datasets==2.14.5\n",
        "\n",
        "# Numeric/scientific computing (pinned for Python 3.9)\n",
        "numpy==1.25.2\n",
        "scikit-learn==1.2.2  # Downgraded for Python 3.9 compatibility\n",
        "pandas==1.5.3  # Last version supporting Python 3.9\n",
        "\n",
        "# NLP specific\n",
        "spacy>=3.0.0\n",
        "en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.0/en_core_web_sm-3.7.0-py3-none-any.whl\n",
        "\n",
        "# FastAPI stack\n",
        "fastapi==0.103.1\n",
        "uvicorn==0.23.2\n",
        "python-multipart==0.0.6\n",
        "jinja2==3.1.2\n",
        "\n",
        "# Pydantic\n",
        "pydantic==2.4.2\n",
        "\n",
        "# Additional utilities\n",
        "tqdm==4.66.1\n",
        "requests==2.31.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEJFsaQTuFbf",
        "outputId": "2b5a9ad2-7802-4121-da06-8ca3555ada34"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile README.md\n",
        "\n",
        "# Email Classification System\n",
        "\n",
        "This project implements an email classification system for a company's support team. The system categorizes incoming support emails into predefined categories while ensuring that personal information (PII) is masked before processing.\n",
        "\n",
        "## Features\n",
        "\n",
        "- Email classification using BERT\n",
        "- PII masking using Named Entity Recognition (NER) and regex patterns\n",
        "- FastAPI-based API for email classification\n",
        "- Supports various PII entity types (full name, email, phone number, etc.)\n",
        "\n",
        "## Setup Instructions\n",
        "\n",
        "### Prerequisites\n",
        "\n",
        "- Python 3.7+\n",
        "- PyTorch\n",
        "- Transformers library\n",
        "- Spacy\n",
        "- FastAPI\n",
        "\n",
        "### Installation\n",
        "\n",
        "1. Clone this repository:\n",
        "```\n",
        "git clone https://github.com/yourusername/email-classification.git\n",
        "cd email-classification\n",
        "```\n",
        "\n",
        "2. Install the required packages:\n",
        "```\n",
        "pip install -r requirements.txt\n",
        "```\n",
        "\n",
        "3. Download the SpaCy English model:\n",
        "```\n",
        "python -m spacy download en_core_web_sm\n",
        "```\n",
        "\n",
        "### Training the Model\n",
        "\n",
        "1. Prepare your training data in a CSV file with 'email' and 'type' columns.\n",
        "2. Run the training script:\n",
        "```python\n",
        "from models import EmailClassifier\n",
        "\n",
        "classifier = EmailClassifier()\n",
        "classifier.train('path/to/your/data.csv', epochs=4, batch_size=16)\n",
        "```\n",
        "\n",
        "### Running the API\n",
        "\n",
        "```\n",
        "python app.py\n",
        "```\n",
        "\n",
        "The API will be available at `http://localhost:8000`.\n",
        "\n",
        "## API Documentation\n",
        "\n",
        "### Classify Email\n",
        "\n",
        "**Endpoint:** `POST /classify`\n",
        "\n",
        "**Request Body:**\n",
        "```json\n",
        "{\n",
        "    \"email_body\": \"Your email text here\"\n",
        "}\n",
        "```\n",
        "\n",
        "**Response:**\n",
        "```json\n",
        "{\n",
        "    \"input_email_body\": \"Original email text\",\n",
        "    \"list_of_masked_entities\": [\n",
        "        {\n",
        "            \"position\": [start_index, end_index],\n",
        "            \"classification\": \"entity_type\",\n",
        "            \"entity\": \"original_entity_value\"\n",
        "        }\n",
        "    ],\n",
        "    \"masked_email\": \"Masked email text\",\n",
        "    \"category_of_the_email\": \"Predicted category\"\n",
        "}\n",
        "```\n",
        "\n",
        "### Health Check\n",
        "\n",
        "**Endpoint:** `GET /health`\n",
        "\n",
        "**Response:**\n",
        "```json\n",
        "{\n",
        "    \"status\": \"ok\",\n",
        "    \"model_loaded\": true\n",
        "}\n",
        "```\n",
        "\n",
        "## Deployment on Hugging Face Spaces\n",
        "\n",
        "1. Create a new Space on Hugging Face with Docker template\n",
        "2. Upload the project files to the Space\n",
        "3. Set up the Space to run the FastAPI application\n",
        "\n",
        "## File Structure\n",
        "\n",
        "- `app.py`: FastAPI application\n",
        "- `models.py`: Email classification model\n",
        "- `utils.py`: PII masking utilities\n",
        "- `requirements.txt`: Required packages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NNhX4VONl-C",
        "outputId": "67f4daad-25e7-4bf9-e70b-431846620d71"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Dockerfile\n",
        "FROM python:3.9-slim\n",
        "\n",
        "WORKDIR /app\n",
        "\n",
        "COPY requirements.txt .\n",
        "RUN pip install --no-cache-dir -r requirements.txt\n",
        "RUN python -m spacy download en_core_web_sm\n",
        "\n",
        "COPY . .\n",
        "\n",
        "CMD [\"uvicorn\", \"app_hf:app\", \"--host\", \"0.0.0.0\", \"--port\", \"7860\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uatyluKMuQ4Y",
        "outputId": "a4e90914-1643-4cd0-ad18-d16fdfabc74c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Dockerfile\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # CPU only\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
      ],
      "metadata": {
        "id": "kEBPC8yxv2ff"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers==4.33.2"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVSrr1nD5dz1",
        "outputId": "70fcdef4-a9ea-4f22-dd1c-7acc253eb6a9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.33.2\n",
            "  Downloading transformers-4.33.2-py3-none-any.whl.metadata (119 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/119.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.2) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.2) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.2) (2.32.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.33.2)\n",
            "  Downloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.2) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.2) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.2) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.2) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.33.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.33.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.33.2) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.33.2) (2025.1.31)\n",
            "Downloading transformers-4.33.2-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m141.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.1\n",
            "    Uninstalling tokenizers-0.21.1:\n",
            "      Successfully uninstalled tokenizers-0.21.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.51.3\n",
            "    Uninstalling transformers-4.51.3:\n",
            "      Successfully uninstalled transformers-4.51.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.33.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tokenizers-0.13.3 transformers-4.33.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the training script\n",
        "#!python train.py --data /content/combined_emails_with_natural_pii.csv --epochs 2 --batch_size 4\n",
        "!python train.py --data /content/combined_emails_with_natural_pii.csv --epochs 4 --batch_size 16 --lr 2e-5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRN35WyxuXtS",
        "outputId": "a6811a94-8382-479f-ecd9-701008a8bed7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "2025-04-19 07:44:25.944568: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745048665.965630    9077 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745048665.972046    9077 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "2025-04-19 07:44:28,855 - INFO - Training model with data from /content/combined_emails_with_natural_pii.csv\n",
            "2025-04-19 07:44:28,884 - INFO - 📦 Using device: cuda\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "2025-04-19 07:44:29,030 - INFO - Loading data from /content/combined_emails_with_natural_pii.csv\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "2025-04-19 07:44:31,636 - INFO - Epoch 1/4\n",
            "2025-04-19 07:51:41,066 - INFO - Average training loss: 0.6603\n",
            "2025-04-19 07:52:22,775 - INFO - Validation accuracy: 0.7540\n",
            "2025-04-19 07:52:22,775 - INFO - Saving best model with accuracy: 0.7540\n",
            "2025-04-19 07:52:23,371 - INFO - Model saved to ./model_data\n",
            "2025-04-19 07:52:23,383 - INFO - Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Incident     0.6479    0.9708    0.7772      1920\n",
            "     Request     0.9165    0.9382    0.9272      1392\n",
            "     Problem     0.7500    0.0565    0.1051      1009\n",
            "      Change     0.9289    0.8184    0.8701       479\n",
            "\n",
            "    accuracy                         0.7540      4800\n",
            "   macro avg     0.8108    0.6960    0.6699      4800\n",
            "weighted avg     0.7753    0.7540    0.6887      4800\n",
            "\n",
            "2025-04-19 07:52:23,384 - INFO - Epoch 2/4\n",
            "2025-04-19 07:59:34,607 - INFO - Average training loss: 0.4800\n",
            "2025-04-19 08:00:16,223 - INFO - Validation accuracy: 0.7733\n",
            "2025-04-19 08:00:16,223 - INFO - Saving best model with accuracy: 0.7733\n",
            "2025-04-19 08:00:17,133 - INFO - Model saved to ./model_data\n",
            "2025-04-19 08:00:17,144 - INFO - Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Incident     0.6716    0.9448    0.7851      1920\n",
            "     Request     0.9417    0.9289    0.9353      1392\n",
            "     Problem     0.6840    0.1824    0.2879      1009\n",
            "      Change     0.9212    0.8789    0.8996       479\n",
            "\n",
            "    accuracy                         0.7733      4800\n",
            "   macro avg     0.8046    0.7337    0.7270      4800\n",
            "weighted avg     0.7775    0.7733    0.7356      4800\n",
            "\n",
            "2025-04-19 08:00:17,144 - INFO - Epoch 3/4\n",
            "2025-04-19 08:07:28,351 - INFO - Average training loss: 0.3929\n",
            "2025-04-19 08:08:09,908 - INFO - Validation accuracy: 0.7835\n",
            "2025-04-19 08:08:09,908 - INFO - Saving best model with accuracy: 0.7835\n",
            "2025-04-19 08:08:10,829 - INFO - Model saved to ./model_data\n",
            "2025-04-19 08:08:10,839 - INFO - Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Incident     0.6979    0.9083    0.7893      1920\n",
            "     Request     0.9438    0.9411    0.9424      1392\n",
            "     Problem     0.6161    0.2735    0.3789      1009\n",
            "      Change     0.9269    0.8998    0.9131       479\n",
            "\n",
            "    accuracy                         0.7835      4800\n",
            "   macro avg     0.7962    0.7557    0.7559      4800\n",
            "weighted avg     0.7749    0.7835    0.7598      4800\n",
            "\n",
            "2025-04-19 08:08:10,839 - INFO - Epoch 4/4\n",
            "2025-04-19 08:15:22,099 - INFO - Average training loss: 0.3052\n",
            "2025-04-19 08:16:03,578 - INFO - Validation accuracy: 0.7877\n",
            "2025-04-19 08:16:03,578 - INFO - Saving best model with accuracy: 0.7877\n",
            "2025-04-19 08:16:04,491 - INFO - Model saved to ./model_data\n",
            "2025-04-19 08:16:04,502 - INFO - Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Incident     0.7303    0.8349    0.7791      1920\n",
            "     Request     0.9302    0.9576    0.9437      1392\n",
            "     Problem     0.5830    0.4143    0.4844      1009\n",
            "      Change     0.9385    0.8914    0.9143       479\n",
            "\n",
            "    accuracy                         0.7877      4800\n",
            "   macro avg     0.7955    0.7746    0.7804      4800\n",
            "weighted avg     0.7781    0.7877    0.7784      4800\n",
            "\n",
            "2025-04-19 08:16:04,506 - INFO - ✅ Training completed. Best validation accuracy: 0.7877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model with a single email containing PII\n",
        "test_email = \"\"\"Subject: Changement de configuration AWS urgent\n",
        "\n",
        "Cher équipe de support client,\n",
        "\n",
        "J'espère que ce message vous trouve en bonne santé. Je vous écris pour demander un changement de configuration urgent concernant notre infrastructure AWS gérée par votre service de gestion AWS. Nous avons identifié un besoin significatif d'améliorer l'efficacité des ressources, ce qui nécessite une attention immédiate.\n",
        "\n",
        "Notre numéro de compte auprès de votre société est <acc_num>, et les services spécifiques concernés relèvent du service de gestion AWS My name is David Kim.. Nous faisons face à des défis avec l'allocation des ressources qui impactent nos opérations quotidiennes, causant des retards et des inefficacités qui pourraient avoir des effets néfastes sur la continuité de notre activité. Il est crucial que nous abordions ces inefficacités rapidement pour maintenir les niveaux de productivité et éviter d'autres perturbations.\n",
        "\n",
        "Nous avons évalué notre configuration actuelle et croyons que l'optimisation de la configuration pourrait conduire à une performance améliorée, une meilleure gestion des ressources et une réduction des coûts. Nous vous demandons gentiment votre assistance experte pour initier les changements nécessaires dès que possible. Merci de nous faire savoir quelles étapes nous devrions entreprendre de notre côté pour faciliter ce processus.\n",
        "\n",
        "De plus, si vous avez besoin de plus de détails concernant notre infrastructure ou nos objectifs d'optimisation, n'hésitez pas à me contacter directement. Mon numéro de contact est <tel_num>.\n",
        "\n",
        "Merci pour votre attention rapide à cette affaire You can reach me at maria.gonzalez@shop.es.. Nous apprécions grandement votre soutien et espérons résoudre ce problème rapidement.\n",
        "\n",
        "Cordialement,\n",
        "\n",
        "<name>\"\"\"\n",
        "\n",
        "!python test.py --email \"$test_email\""
      ],
      "metadata": {
        "id": "4I2PhXWwwXS_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18db64a6-fb85-4aee-e2e3-c2bb5c2c1c78"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "2025-04-19 08:24:46.723909: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745051086.744920   19586 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745051086.751550   19586 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "2025-04-19 08:24:52,317 - INFO - Model loaded from ./model_data\n",
            "2025-04-19 08:24:52,317 - INFO - Masking PII...\n",
            "2025-04-19 08:24:52,986 - INFO - Classifying email...\n",
            "2025-04-19 08:24:53,198 - INFO - Results:\n",
            "2025-04-19 08:24:53,198 - INFO - Category: Change\n",
            "2025-04-19 08:24:53,198 - INFO - Masked email: Subject: Changement de configuration AWS urgent\n",
            "\n",
            "[full_name] équipe de support client,\n",
            "\n",
            "J'espère que ce message vous trouve en bonne [full_name]. Je vous écris pour demander un changement de configuration urgent concernant notre infrastructure AWS gérée par votre service de gestion AWS. Nous avons identifié un besoin significatif d'améliorer l'efficacité des ressources, ce qui nécessite une attention immédiate.\n",
            "\n",
            "Notre numéro de compte auprès de votre société est <acc_num>, et les services spécifiques concernés relèvent du service de gestion AWS My name is [full_name].. Nous faisons face à des défis avec l'allocation des ressources qui impactent nos opérations quotidiennes, causant des retards et des inefficacités qui pourraient avoir des effets néfastes sur la continuité de notre activité. Il est crucial que nous abordions ces inefficacités rapidement pour maintenir les niveaux de productivité et éviter d'autres perturbations.\n",
            "\n",
            "Nous avons [full_name] et croyons que l'optimisation de la configuration pourrait conduire à une performance améliorée, une meilleure gestion des ressources et une réduction des coûts. Nous vous demandons gentiment votre assistance experte pour initier les changements nécessaires dès que possible. Merci de nous faire savoir quelles étapes nous devrions entreprendre [full_name] côté pour faciliter ce processus.\n",
            "\n",
            "De plus, si vous avez besoin de plus de détails concernant notre infrastructure ou nos objectifs d'optimisation, n'hésitez pas à me contacter directement. Mon numéro de contact est <tel_num>.\n",
            "\n",
            "Merci pour votre attention rapide à cette affaire You can reach me a[email]es.. Nous apprécions grandement [full_name] et espérons [full_name] problème rapidement.\n",
            "\n",
            "Cordialement,\n",
            "\n",
            "<name>\n",
            "2025-04-19 08:24:53,198 - INFO - Found 8 PII entities\n",
            "{\n",
            "  \"input_email_body\": \"Subject: Changement de configuration AWS urgent\\n\\nCher \\u00e9quipe de support client,\\n\\nJ'esp\\u00e8re que ce message vous trouve en bonne sant\\u00e9. Je vous \\u00e9cris pour demander un changement de configuration urgent concernant notre infrastructure AWS g\\u00e9r\\u00e9e par votre service de gestion AWS. Nous avons identifi\\u00e9 un besoin significatif d'am\\u00e9liorer l'efficacit\\u00e9 des ressources, ce qui n\\u00e9cessite une attention imm\\u00e9diate.\\n\\nNotre num\\u00e9ro de compte aupr\\u00e8s de votre soci\\u00e9t\\u00e9 est <acc_num>, et les services sp\\u00e9cifiques concern\\u00e9s rel\\u00e8vent du service de gestion AWS My name is David Kim.. Nous faisons face \\u00e0 des d\\u00e9fis avec l'allocation des ressources qui impactent nos op\\u00e9rations quotidiennes, causant des retards et des inefficacit\\u00e9s qui pourraient avoir des effets n\\u00e9fastes sur la continuit\\u00e9 de notre activit\\u00e9. Il est crucial que nous abordions ces inefficacit\\u00e9s rapidement pour maintenir les niveaux de productivit\\u00e9 et \\u00e9viter d'autres perturbations.\\n\\nNous avons \\u00e9valu\\u00e9 notre configuration actuelle et croyons que l'optimisation de la configuration pourrait conduire \\u00e0 une performance am\\u00e9lior\\u00e9e, une meilleure gestion des ressources et une r\\u00e9duction des co\\u00fbts. Nous vous demandons gentiment votre assistance experte pour initier les changements n\\u00e9cessaires d\\u00e8s que possible. Merci de nous faire savoir quelles \\u00e9tapes nous devrions entreprendre de notre c\\u00f4t\\u00e9 pour faciliter ce processus.\\n\\nDe plus, si vous avez besoin de plus de d\\u00e9tails concernant notre infrastructure ou nos objectifs d'optimisation, n'h\\u00e9sitez pas \\u00e0 me contacter directement. Mon num\\u00e9ro de contact est <tel_num>.\\n\\nMerci pour votre attention rapide \\u00e0 cette affaire You can reach me at maria.gonzalez@shop.es.. Nous appr\\u00e9cions grandement votre soutien et esp\\u00e9rons r\\u00e9soudre ce probl\\u00e8me rapidement.\\n\\nCordialement,\\n\\n<name>\",\n",
            "  \"list_of_masked_entities\": [\n",
            "    {\n",
            "      \"position\": [\n",
            "        49,\n",
            "        53\n",
            "      ],\n",
            "      \"classification\": \"full_name\",\n",
            "      \"entity\": \"Cher\"\n",
            "    },\n",
            "    {\n",
            "      \"position\": [\n",
            "        126,\n",
            "        131\n",
            "      ],\n",
            "      \"classification\": \"full_name\",\n",
            "      \"entity\": \"sant\\u00e9\"\n",
            "    },\n",
            "    {\n",
            "      \"position\": [\n",
            "        549,\n",
            "        558\n",
            "      ],\n",
            "      \"classification\": \"full_name\",\n",
            "      \"entity\": \"David Kim\"\n",
            "    },\n",
            "    {\n",
            "      \"position\": [\n",
            "        938,\n",
            "        973\n",
            "      ],\n",
            "      \"classification\": \"full_name\",\n",
            "      \"entity\": \"\\u00e9valu\\u00e9 notre configuration actuelle\"\n",
            "    },\n",
            "    {\n",
            "      \"position\": [\n",
            "        1319,\n",
            "        1327\n",
            "      ],\n",
            "      \"classification\": \"full_name\",\n",
            "      \"entity\": \"de notre\"\n",
            "    },\n",
            "    {\n",
            "      \"position\": [\n",
            "        1626,\n",
            "        1648\n",
            "      ],\n",
            "      \"classification\": \"email\",\n",
            "      \"entity\": \"maria.gonzalez@shop.es\"\n",
            "    },\n",
            "    {\n",
            "      \"position\": [\n",
            "        1678,\n",
            "        1691\n",
            "      ],\n",
            "      \"classification\": \"full_name\",\n",
            "      \"entity\": \"votre soutien\"\n",
            "    },\n",
            "    {\n",
            "      \"position\": [\n",
            "        1704,\n",
            "        1715\n",
            "      ],\n",
            "      \"classification\": \"full_name\",\n",
            "      \"entity\": \"r\\u00e9soudre ce\"\n",
            "    }\n",
            "  ],\n",
            "  \"masked_email\": \"Subject: Changement de configuration AWS urgent\\n\\n[full_name] \\u00e9quipe de support client,\\n\\nJ'esp\\u00e8re que ce message vous trouve en bonne [full_name]. Je vous \\u00e9cris pour demander un changement de configuration urgent concernant notre infrastructure AWS g\\u00e9r\\u00e9e par votre service de gestion AWS. Nous avons identifi\\u00e9 un besoin significatif d'am\\u00e9liorer l'efficacit\\u00e9 des ressources, ce qui n\\u00e9cessite une attention imm\\u00e9diate.\\n\\nNotre num\\u00e9ro de compte aupr\\u00e8s de votre soci\\u00e9t\\u00e9 est <acc_num>, et les services sp\\u00e9cifiques concern\\u00e9s rel\\u00e8vent du service de gestion AWS My name is [full_name].. Nous faisons face \\u00e0 des d\\u00e9fis avec l'allocation des ressources qui impactent nos op\\u00e9rations quotidiennes, causant des retards et des inefficacit\\u00e9s qui pourraient avoir des effets n\\u00e9fastes sur la continuit\\u00e9 de notre activit\\u00e9. Il est crucial que nous abordions ces inefficacit\\u00e9s rapidement pour maintenir les niveaux de productivit\\u00e9 et \\u00e9viter d'autres perturbations.\\n\\nNous avons [full_name] et croyons que l'optimisation de la configuration pourrait conduire \\u00e0 une performance am\\u00e9lior\\u00e9e, une meilleure gestion des ressources et une r\\u00e9duction des co\\u00fbts. Nous vous demandons gentiment votre assistance experte pour initier les changements n\\u00e9cessaires d\\u00e8s que possible. Merci de nous faire savoir quelles \\u00e9tapes nous devrions entreprendre [full_name] c\\u00f4t\\u00e9 pour faciliter ce processus.\\n\\nDe plus, si vous avez besoin de plus de d\\u00e9tails concernant notre infrastructure ou nos objectifs d'optimisation, n'h\\u00e9sitez pas \\u00e0 me contacter directement. Mon num\\u00e9ro de contact est <tel_num>.\\n\\nMerci pour votre attention rapide \\u00e0 cette affaire You can reach me a[email]es.. Nous appr\\u00e9cions grandement [full_name] et esp\\u00e9rons [full_name] probl\\u00e8me rapidement.\\n\\nCordialement,\\n\\n<name>\",\n",
            "  \"category_of_the_email\": \"Change\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import requests\n",
        "import json\n",
        "import socket\n",
        "\n",
        "# Start the FastAPI server\n",
        "server_process = subprocess.Popen(['python', '-m', 'uvicorn', 'app:app', '--host', '0.0.0.0', '--port', '8000'])\n",
        "print(\"Server started, waiting for it to initialize...\")\n",
        "\n",
        "# Wait until server is ready\n",
        "def wait_for_server(host, port, timeout=90):\n",
        "    start_time = time.time()\n",
        "    while time.time() - start_time < timeout:\n",
        "        try:\n",
        "            with socket.create_connection((host, port), timeout=2):\n",
        "                print(\"Server is up!\")\n",
        "                return\n",
        "        except OSError:\n",
        "            time.sleep(1)\n",
        "    raise RuntimeError(\"Server didn't start within timeout.\")\n",
        "\n",
        "wait_for_server(\"localhost\", 8000)\n",
        "\n",
        "# Test the API\n",
        "test_email = \"\"\"Subject: Multiple Issues with Account and Billing\n",
        "\n",
        "Dear Support Team,\n",
        "\n",
        "I'm experiencing several problems with my account and recent charges. I've been a customer for 5 years and need urgent assistance.\n",
        "\n",
        "My account details:\n",
        "Name: Robert Johnson\n",
        "Email: robert.johnson@emailprovider.com\n",
        "Phone: (555) 123-4567\n",
        "DOB: 03/12/1978\n",
        "Account ID: A-45678\n",
        "Aadhar: 8765 4321 9876 5432\n",
        "\n",
        "I noticed several unauthorized charges on my credit card (4444-3333-2222-1111, expiry 09/26, CVV 555) last month.\n",
        "\n",
        "Additionally, I'm unable to access certain premium features I've paid for. When I try to log in from my secondary email (robert.j.work@company.org), it says my subscription has expired.\n",
        "\n",
        "I've tried contacting billing department at your toll-free number 1-800-555-9876 but couldn't get through.\n",
        "\n",
        "Please help me resolve these issues as soon as possible. You can reach me at my alternate number +1-555-987-6543.\n",
        "\n",
        "Best regards,\n",
        "Robert Johnson\"\"\"\n",
        "response = requests.post('http://localhost:8000/classify', json={'email_body': test_email})\n",
        "\n",
        "if response.status_code == 200:\n",
        "    print(\"API Request Successful!\")\n",
        "    print(json.dumps(response.json(), indent=2))\n",
        "else:\n",
        "    print(f\"Error: {response.status_code}\")\n",
        "    print(response.text)\n",
        "\n",
        "# Clean up\n",
        "server_process.terminate()\n",
        "print(\"Server stopped.\")"
      ],
      "metadata": {
        "id": "_bzFq9F4KP1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a zip file of all necessary files for Hugging Face deployment\n",
        "!zip -r email_classifier.zip app_hf.py templates/ models.py utils.py requirements.txt Dockerfile model_data/ README.md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUKx9OqAMcNf",
        "outputId": "577b1d6a-90b5-4bc3-d425-9fe2b4170ae1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: app_hf.py (deflated 73%)\n",
            "  adding: templates/ (stored 0%)\n",
            "  adding: templates/index.html (deflated 68%)\n",
            "  adding: models.py (deflated 72%)\n",
            "  adding: utils.py (deflated 65%)\n",
            "  adding: requirements.txt (deflated 34%)\n",
            "  adding: Dockerfile (deflated 24%)\n",
            "  adding: model_data/ (stored 0%)\n",
            "  adding: model_data/tokenizer_config.json (deflated 45%)\n",
            "  adding: model_data/pytorch_model.bin (deflated 7%)\n",
            "  adding: model_data/special_tokens_map.json (deflated 42%)\n",
            "  adding: model_data/config.json (deflated 52%)\n",
            "  adding: model_data/vocab.txt (deflated 53%)\n",
            "  adding: model_data/label_mapping.pkl (deflated 16%)\n",
            "  adding: README.md (deflated 51%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VUH1GG8Vei95"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}